{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from utils import plot_sparsity_matrix,weight_histograms,set_all_seeds\n",
    "from dataset import get_mnist_loader\n",
    "from pruning import threshold_prune,save_sparse_weights,count_nonzero_weights\n",
    "import datetime\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dataset\n",
    "\n",
    "# Configuration"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5),(0.5))])\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 20\n",
    "LR = 1e-3\n",
    "MU = 0.9\n",
    "LAMBDA = 1e-2\n",
    "S = 2\n",
    "\n",
    "SEED = 42\n",
    "CLASSES = [0,1,2,3,4,5,6,7,8,9]\n",
    "TIMESTAMP = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# Try to get GPU device\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "checkpoint_path = '../checkpoints/'\n",
    "set_all_seeds(SEED)\n",
    "\n",
    "trainloader,testloader = get_mnist_loader(transform,BATCH_SIZE)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Print images from dataset and their labels"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "1 2 8 5\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from utils import imshow\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "print(images.shape, labels.shape)\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images[0:4]))\n",
    "# print labels\n",
    "print(' '.join(f'{labels[j]:1d}' for j in range(4)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# LeNet-300-100\n",
    "\n",
    "LeNet-300-100 is a Fully-Connected neural network, presented in [[1](#1)].\n",
    "It is composed by two hidden layers, with respectively 300 and 100 units."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": "LeNet300(\n  (fc1): Linear(in_features=784, out_features=300, bias=True)\n  (fc2): Linear(in_features=300, out_features=100, bias=True)\n  (fc3): Linear(in_features=100, out_features=10, bias=True)\n)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.lenet import LeNet300\n",
    "\n",
    "net = LeNet300(10)\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "print(device)\n",
    "net.to(device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.optim.lr_scheduler as sched\n",
    "from train import MyMultiStepLR\n",
    "\n",
    "loss_fn = F.cross_entropy\n",
    "optimizer = optim.SGD(net.parameters(), lr=LR,momentum=MU, weight_decay=LAMBDA)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Epoch: 001/020 | Batch:0000/0469 | Loss: 2.299\n",
      "***Epoch: 001/020 | Batch:0100/0469 | Loss: 2.109\n",
      "***Epoch: 001/020 | Batch:0200/0469 | Loss: 1.716\n",
      "***Epoch: 001/020 | Batch:0300/0469 | Loss: 1.208\n",
      "***Epoch: 001/020 | Batch:0400/0469 | Loss: 0.843\n",
      "***Epoch: 001/020 | Train. Acc.: 81.440% | Loss: 0.743\n",
      "Epoch: 001/020 | Train accuracy: 81.44% | Validation accuracy: 81.81% | Train loss: 0.743| Validation loss: 0.726| Best Validation (Ep. 000): -inf%\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Parent directory checkpoints does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_22160\\2480431651.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m loss, train_acc, val_acc = training_loop(EPOCHS,net,optimizer,device,trainloader,testloader,loss_fn,100,\n\u001B[1;32m----> 7\u001B[1;33m                                          None,'checkpoints/mnist-lenet300-100.pth',writer)\n\u001B[0m\u001B[0;32m      8\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[0mwriter\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0madd_hparams\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m{\u001B[0m\u001B[1;34m'epochs'\u001B[0m\u001B[1;33m:\u001B[0m\u001B[0mEPOCHS\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;34m'learning rate'\u001B[0m\u001B[1;33m:\u001B[0m\u001B[0mLR\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;34m'lambda'\u001B[0m\u001B[1;33m:\u001B[0m\u001B[0mLAMBDA\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;34m'momentum'\u001B[0m\u001B[1;33m:\u001B[0m\u001B[0mMU\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m{\u001B[0m\u001B[1;34m'loss'\u001B[0m\u001B[1;33m:\u001B[0m\u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mloss\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;34m'train_accuracy'\u001B[0m\u001B[1;33m:\u001B[0m\u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrain_acc\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmax\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;34m'validation accuracy'\u001B[0m\u001B[1;33m:\u001B[0m\u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mval_acc\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmax\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;34m'compression'\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\DataspellProjects\\model-compression\\train.py\u001B[0m in \u001B[0;36mtraining_loop\u001B[1;34m(epochs, model, optimizer, device, train_loader, valid_loader, loss_fn, logging_interval, scheduler, checkpoint_path, writer)\u001B[0m\n\u001B[0;32m     85\u001B[0m                 \u001B[0mbest_valid_acc\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbest_epoch\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mvalid_acc\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mepoch\u001B[0m \u001B[1;33m+\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     86\u001B[0m                 \u001B[1;32mif\u001B[0m \u001B[0mcheckpoint_path\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 87\u001B[1;33m                     \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msave\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstate_dict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcheckpoint_path\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     88\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     89\u001B[0m         \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'Time elapsed: %.2f min'\u001B[0m \u001B[1;33m%\u001B[0m \u001B[1;33m(\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtime\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtime\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0mstart_time\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m/\u001B[0m \u001B[1;36m60\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\miniconda3\\envs\\pytorch\\lib\\site-packages\\torch\\serialization.py\u001B[0m in \u001B[0;36msave\u001B[1;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001B[0m\n\u001B[0;32m    420\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    421\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0m_use_new_zipfile_serialization\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 422\u001B[1;33m         \u001B[1;32mwith\u001B[0m \u001B[0m_open_zipfile_writer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mf\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mopened_zipfile\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    423\u001B[0m             \u001B[0m_save\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mobj\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mopened_zipfile\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpickle_module\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpickle_protocol\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    424\u001B[0m             \u001B[1;32mreturn\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\miniconda3\\envs\\pytorch\\lib\\site-packages\\torch\\serialization.py\u001B[0m in \u001B[0;36m_open_zipfile_writer\u001B[1;34m(name_or_buffer)\u001B[0m\n\u001B[0;32m    307\u001B[0m     \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    308\u001B[0m         \u001B[0mcontainer\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_open_zipfile_writer_buffer\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 309\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0mcontainer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mname_or_buffer\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    310\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    311\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\miniconda3\\envs\\pytorch\\lib\\site-packages\\torch\\serialization.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, name)\u001B[0m\n\u001B[0;32m    285\u001B[0m \u001B[1;32mclass\u001B[0m \u001B[0m_open_zipfile_writer_file\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0m_opener\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    286\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m__init__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m->\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 287\u001B[1;33m         \u001B[0msuper\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0m_open_zipfile_writer_file\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__init__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_C\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mPyTorchFileWriter\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    288\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    289\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m__exit__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m->\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Parent directory checkpoints does not exist."
     ]
    }
   ],
   "source": [
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from train import training_loop\n",
    "\n",
    "writer = SummaryWriter('runs/mnist/lenet300-100/%s' % TIMESTAMP)\n",
    "\n",
    "loss, train_acc, val_acc = training_loop(EPOCHS,net,optimizer,device,trainloader,testloader,loss_fn,100,\n",
    "                                         None,'checkpoints/mnist-lenet300-100.pth',writer)\n",
    "\n",
    "writer.add_hparams({'epochs':EPOCHS,'learning rate':LR,'lambda':LAMBDA,'momentum':MU},{'loss':np.array(loss).min(),'train_accuracy':np.array(train_acc).max(),'validation accuracy':np.array(val_acc).max(),'compression':1})\n",
    "writer.add_scalar('total parameters',count_nonzero_weights(net))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# visualization loss\n",
    "plt.plot(loss)\n",
    "plt.xlabel(\"Number of iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"CNN: Loss vs Number of iteration\")\n",
    "plt.show()\n",
    "\n",
    "# visualization accuracy\n",
    "plt.plot(train_acc,color = \"red\")\n",
    "plt.plot(val_acc,color = \"blue\")\n",
    "plt.xlabel(\"Number of iteration\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"CNN: Accuracy vs Number of iteration\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pruning import threshold_prune\n",
    "\n",
    "net = LeNet300(10)\n",
    "net.load_state_dict(torch.load('checkpoints/mnist-lenet300-100.pth'))\n",
    "\n",
    "cf = threshold_prune(net,S)\n",
    "\n",
    "writer = SummaryWriter('runs/mnist/lenet300-100-pruned/%s' % TIMESTAMP)\n",
    "\n",
    "writer.add_scalar('compression factor',cf)\n",
    "weight_histograms(writer,None,net)\n",
    "\n",
    "plot_sparsity_matrix(net)\n",
    "torch.save(net.state_dict(),'checkpoints/mnist-lenet300-100-pruned.pth')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can see that the fc1 layer is divided in 28 vertical bands, whose width is 28, corresponding to the $28 \\times 28$ input pixel.\n",
    "As stated in [[2](#2)], network pruning detects visual attention regions: the colored regions, correspond to non-zero parameters, are more dense in the center of the image, since the digits are written in the center."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from train import evaluate\n",
    "\n",
    "net.load_state_dict(torch.load('checkpoints/mnist-lenet300-100-pruned.pth'))\n",
    "net.to(device)\n",
    "\n",
    "valid_acc, valid_loss = evaluate(net, testloader, device, loss_fn)\n",
    "\n",
    "print('Accuracy after pruning: %.3f%% | Loss: %.3f' % (\n",
    "        valid_acc, valid_loss))\n",
    "\n",
    "writer = SummaryWriter('runs/mnist/lenet300-100-retrained/%s' % TIMESTAMP)\n",
    "optimizer = optim.SGD(net.parameters(), lr=LR,momentum=MU,weight_decay=LAMBDA)\n",
    "\n",
    "\n",
    "loss, train_acc, val_acc = training_loop(EPOCHS,net,optimizer,device,trainloader,testloader,loss_fn,100,\n",
    "                                         None,'checkpoints/mnist-lenet300-100-retrained.pth',writer)\n",
    "\n",
    "writer.add_hparams({'epochs':EPOCHS,'learning rate':LR,'lambda':LAMBDA,'momentum':MU},{'loss':np.array(loss).min(),'train_accuracy':np.array(train_acc).max(),'validation accuracy':np.array(val_acc).max(),'compression':cf})\n",
    "\n",
    "torch.save(net.state_dict(),'checkpoints/mnist-lenet300-100-finetuned.pth')\n",
    "\n",
    "plot_sparsity_matrix(net)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# LeNet-5\n",
    "\n",
    "![Lenet5](./assets/lenet-5_1.jpg \"LeNet 5\")\n",
    "\n",
    "The input is a $32 \\times 32$ image, since [[2](#2)] found desirable to have distinctive features of each character in the center of the receptive field of the highest-level feature detectors.\n",
    "\n",
    "- C1 is a convolutional layer with 6 feature maps and a kernel of $5 \\times 5$.\n",
    "- S\n",
    "\n",
    "Images need to be rescaled to size 32x32 as described in LeCun et al. 1998"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5),(0.5)),\n",
    "     transforms.Resize(32)])\n",
    "# Load datasets\n",
    "trainloader,testloader = get_mnist_loader(transform,BATCH_SIZE)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "print(images.shape, labels.shape)\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images[0:4]))\n",
    "# print labels\n",
    "print(' '.join(f'{labels[j]:1d}' for j in range(4)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from models.lenet import LeNet5\n",
    "\n",
    "net = LeNet5(10)\n",
    "# Try to get GPU device\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "print(device)\n",
    "net.to(device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from train import training_loop\n",
    "\n",
    "loss_fn = F.cross_entropy\n",
    "optimizer = optim.SGD(net.parameters(), lr=LR,momentum=MU,weight_decay=LAMBDA)\n",
    "\n",
    "lrs = MyMultiStepLR({0:5e-4,2:2e-4,5:1e-4,8:5e-5,12:1e-5})\n",
    "# scheduler = sched.LambdaLR(optimizer,  lrs.get_lr,last_epoch=-1,verbose=True)\n",
    "\n",
    "writer = SummaryWriter('runs/mnist/lenet-5/%s' % TIMESTAMP)\n",
    "\n",
    "loss, train_acc, val_acc = training_loop(EPOCHS,net,optimizer,device,trainloader,testloader,loss_fn,100,None\n",
    "                                         ,'checkpoints/mnist-lenet5.pth',writer)\n",
    "\n",
    "writer.add_hparams({'epochs':EPOCHS,'learning rate':LR,'lambda':LAMBDA,'momentum':MU},{'loss':np.array(loss).min(),'train_accuracy':np.array(train_acc).max(),'validation accuracy':np.array(val_acc).max(),'compression':1})\n",
    "\n",
    "writer.add_scalar('total parameters',count_nonzero_weights(net))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# visualization loss\n",
    "plt.plot(loss)\n",
    "plt.xlabel(\"Number of iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"CNN: Loss vs Number of iteration\")\n",
    "plt.show()\n",
    "\n",
    "# visualization accuracy\n",
    "plt.plot(train_acc,color = \"red\")\n",
    "plt.plot(val_acc,color = \"blue\")\n",
    "plt.xlabel(\"Number of iteration\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"CNN: Accuracy vs Number of iteration\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "net = LeNet5(10)\n",
    "net.load_state_dict(torch.load('checkpoints/mnist-lenet5.pth'))\n",
    "net.to(device)\n",
    "\n",
    "cf = threshold_prune(net,S)\n",
    "\n",
    "writer = SummaryWriter('runs/mnist/lenet5-pruned/%s' % TIMESTAMP)\n",
    "\n",
    "writer.add_scalar('compression factor',cf)\n",
    "weight_histograms(writer,None,net)\n",
    "torch.save(net.state_dict(),'checkpoints/mnist-lenet5-pruned.pth')\n",
    "\n",
    "valid_acc, valid_loss = evaluate(net, testloader, device, loss_fn)\n",
    "\n",
    "print('Accuracy after pruning: %.3f%% | Loss: %.3f' % (\n",
    "        valid_acc, valid_loss))\n",
    "\n",
    "optimizer = optim.SGD(net.parameters(), lr=LR,momentum=MU,weight_decay=LAMBDA)\n",
    "writer = SummaryWriter('runs/mnist/lenet5-retrained/%s' % TIMESTAMP)\n",
    "\n",
    "loss, train_acc, val_acc = training_loop(EPOCHS,net,optimizer,device,trainloader,testloader,loss_fn,100,\n",
    "                                         None,'checkpoints/mnist-lenet5-retrained.pth',writer)\n",
    "\n",
    "torch.save(net.state_dict(),'checkpoints/mnist-lenet5-finetuned.pth')\n",
    "\n",
    "writer.add_hparams({'epochs':EPOCHS,'learning rate':LR,'lambda':LAMBDA,'momentum':MU},{'loss':np.array(loss).min(),'train_accuracy':np.array(train_acc).max(),'validation accuracy':np.array(val_acc).max(),'compression':cf})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "weight_histograms(writer,None,net)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# can duplicate parameters if shared\n",
    "from models.lenet import LeNet300\n",
    "import torch\n",
    "import os\n",
    "\n",
    "from quantization import quantize\n",
    "from pruning import threshold_prune,apply_prune\n",
    "\n",
    "os.environ[\"OMP_NUM_THREADS\"] = '1'\n",
    "\n",
    "net = LeNet300(10)\n",
    "net.load_state_dict(torch.load('checkpoints/mnist-lenet300-100.pth'))\n",
    "\n",
    "threshold_prune(net,2)\n",
    "apply_prune(net)\n",
    "\n",
    "quantize(net,5)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# References\n",
    "<a id=\"1\">[1]</a> LeCun, Yann, et al. \"Gradient-based learning applied to document recognition.\" Proceedings of the IEEE 86.11 (1998): 2278-2324.\n",
    "<a id=\"2\">[2]</a> Han, Song, et al. \"Learning both weights and connections for efficient neural network.\" Advances in neural information processing systems 28 (2015)."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
