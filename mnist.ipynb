{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from utils import plot_sparsity_matrix,weight_histograms,set_all_seeds\n",
    "from dataset import get_mnist_loader\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5),(0.5))])\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 20\n",
    "SEED = 42\n",
    "CLASSES = [0,1,2,3,4,5,6,7,8,9]\n",
    "TIMESTAMP = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# Try to get GPU device\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "set_all_seeds(SEED)\n",
    "\n",
    "trainloader,testloader = get_mnist_loader(transform,BATCH_SIZE)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Print images from dataset and their labels"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "1 2 8 5\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from utils import imshow\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "print(images.shape, labels.shape)\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images[0:4]))\n",
    "# print labels\n",
    "print(' '.join(f'{labels[j]:1d}' for j in range(4)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# LeNet-300-100"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": "LeNet300(\n  (fc1): Linear(in_features=784, out_features=300, bias=True)\n  (fc2): Linear(in_features=300, out_features=100, bias=True)\n  (fc3): Linear(in_features=100, out_features=10, bias=True)\n)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.lenet import LeNet300\n",
    "\n",
    "net = LeNet300(10)\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "print(device)\n",
    "net.to(device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x0000012CCFCC2F78>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Dario\\miniconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1466, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"C:\\Users\\Dario\\miniconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1430, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"C:\\Users\\Dario\\miniconda3\\envs\\pytorch\\lib\\multiprocessing\\process.py\", line 140, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"C:\\Users\\Dario\\miniconda3\\envs\\pytorch\\lib\\multiprocessing\\popen_spawn_win32.py\", line 104, in wait\n",
      "    res = _winapi.WaitForSingleObject(int(self._handle), msecs)\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.optim.lr_scheduler as sched\n",
    "from train import MyMultiStepLR\n",
    "\n",
    "loss_fn = F.cross_entropy\n",
    "optimizer = optim.SGD(net.parameters(), lr=1e-3,momentum=0.9, weight_decay=1e-5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Epoch: 001/020 | Batch:0000/0469 | Loss: 2.299\n",
      "***Epoch: 001/020 | Batch:0100/0469 | Loss: 2.104\n",
      "***Epoch: 001/020 | Batch:0200/0469 | Loss: 1.686\n",
      "***Epoch: 001/020 | Batch:0300/0469 | Loss: 1.163\n",
      "***Epoch: 001/020 | Batch:0400/0469 | Loss: 0.803\n",
      "***Epoch: 001/020 | Train. Acc.: 82.003% | Loss: 0.708\n",
      "Epoch: 001/020 | Train accuracy: 82.00% | Validation accuracy: 82.46% | Train loss: 0.708| Validation loss: 0.691| Best Validation (Ep. 000): -inf%\n",
      "Time elapsed: 0.32 min\n",
      "***Epoch: 002/020 | Batch:0000/0469 | Loss: 0.657\n",
      "***Epoch: 002/020 | Batch:0100/0469 | Loss: 0.700\n",
      "***Epoch: 002/020 | Batch:0200/0469 | Loss: 0.490\n",
      "***Epoch: 002/020 | Batch:0300/0469 | Loss: 0.590\n",
      "***Epoch: 002/020 | Batch:0400/0469 | Loss: 0.444\n",
      "***Epoch: 002/020 | Train. Acc.: 87.977% | Loss: 0.437\n",
      "Epoch: 002/020 | Train accuracy: 87.98% | Validation accuracy: 88.31% | Train loss: 0.437| Validation loss: 0.421| Best Validation (Ep. 001): 82.46%\n",
      "Time elapsed: 0.62 min\n",
      "***Epoch: 003/020 | Batch:0000/0469 | Loss: 0.508\n",
      "***Epoch: 003/020 | Batch:0100/0469 | Loss: 0.321\n",
      "***Epoch: 003/020 | Batch:0200/0469 | Loss: 0.407\n",
      "***Epoch: 003/020 | Batch:0300/0469 | Loss: 0.366\n",
      "***Epoch: 003/020 | Batch:0400/0469 | Loss: 0.315\n",
      "***Epoch: 003/020 | Train. Acc.: 89.292% | Loss: 0.371\n",
      "Epoch: 003/020 | Train accuracy: 89.29% | Validation accuracy: 89.66% | Train loss: 0.371| Validation loss: 0.357| Best Validation (Ep. 002): 88.31%\n",
      "Time elapsed: 0.91 min\n",
      "***Epoch: 004/020 | Batch:0000/0469 | Loss: 0.339\n",
      "***Epoch: 004/020 | Batch:0100/0469 | Loss: 0.347\n",
      "***Epoch: 004/020 | Batch:0200/0469 | Loss: 0.319\n",
      "***Epoch: 004/020 | Batch:0300/0469 | Loss: 0.475\n",
      "***Epoch: 004/020 | Batch:0400/0469 | Loss: 0.366\n",
      "***Epoch: 004/020 | Train. Acc.: 90.278% | Loss: 0.339\n",
      "Epoch: 004/020 | Train accuracy: 90.28% | Validation accuracy: 90.40% | Train loss: 0.339| Validation loss: 0.327| Best Validation (Ep. 003): 89.66%\n",
      "Time elapsed: 1.20 min\n",
      "***Epoch: 005/020 | Batch:0000/0469 | Loss: 0.356\n",
      "***Epoch: 005/020 | Batch:0100/0469 | Loss: 0.255\n",
      "***Epoch: 005/020 | Batch:0200/0469 | Loss: 0.336\n",
      "***Epoch: 005/020 | Batch:0300/0469 | Loss: 0.653\n",
      "***Epoch: 005/020 | Batch:0400/0469 | Loss: 0.381\n",
      "***Epoch: 005/020 | Train. Acc.: 90.830% | Loss: 0.316\n",
      "Epoch: 005/020 | Train accuracy: 90.83% | Validation accuracy: 91.04% | Train loss: 0.316| Validation loss: 0.307| Best Validation (Ep. 004): 90.40%\n",
      "Time elapsed: 1.48 min\n",
      "***Epoch: 006/020 | Batch:0000/0469 | Loss: 0.303\n",
      "***Epoch: 006/020 | Batch:0100/0469 | Loss: 0.348\n",
      "***Epoch: 006/020 | Batch:0200/0469 | Loss: 0.237\n",
      "***Epoch: 006/020 | Batch:0300/0469 | Loss: 0.338\n",
      "***Epoch: 006/020 | Batch:0400/0469 | Loss: 0.375\n",
      "***Epoch: 006/020 | Train. Acc.: 91.257% | Loss: 0.300\n",
      "Epoch: 006/020 | Train accuracy: 91.26% | Validation accuracy: 91.47% | Train loss: 0.300| Validation loss: 0.291| Best Validation (Ep. 005): 91.04%\n",
      "Time elapsed: 1.77 min\n",
      "***Epoch: 007/020 | Batch:0000/0469 | Loss: 0.274\n",
      "***Epoch: 007/020 | Batch:0100/0469 | Loss: 0.505\n",
      "***Epoch: 007/020 | Batch:0200/0469 | Loss: 0.334\n",
      "***Epoch: 007/020 | Batch:0300/0469 | Loss: 0.215\n",
      "***Epoch: 007/020 | Batch:0400/0469 | Loss: 0.221\n",
      "***Epoch: 007/020 | Train. Acc.: 91.590% | Loss: 0.290\n",
      "Epoch: 007/020 | Train accuracy: 91.59% | Validation accuracy: 91.84% | Train loss: 0.290| Validation loss: 0.281| Best Validation (Ep. 006): 91.47%\n",
      "Time elapsed: 2.05 min\n",
      "***Epoch: 008/020 | Batch:0000/0469 | Loss: 0.274\n",
      "***Epoch: 008/020 | Batch:0100/0469 | Loss: 0.422\n",
      "***Epoch: 008/020 | Batch:0200/0469 | Loss: 0.263\n",
      "***Epoch: 008/020 | Batch:0300/0469 | Loss: 0.347\n",
      "***Epoch: 008/020 | Batch:0400/0469 | Loss: 0.348\n",
      "***Epoch: 008/020 | Train. Acc.: 92.028% | Loss: 0.273\n",
      "Epoch: 008/020 | Train accuracy: 92.03% | Validation accuracy: 92.29% | Train loss: 0.273| Validation loss: 0.267| Best Validation (Ep. 007): 91.84%\n",
      "Time elapsed: 2.33 min\n",
      "***Epoch: 009/020 | Batch:0000/0469 | Loss: 0.275\n",
      "***Epoch: 009/020 | Batch:0100/0469 | Loss: 0.234\n",
      "***Epoch: 009/020 | Batch:0200/0469 | Loss: 0.269\n",
      "***Epoch: 009/020 | Batch:0300/0469 | Loss: 0.277\n",
      "***Epoch: 009/020 | Batch:0400/0469 | Loss: 0.248\n",
      "***Epoch: 009/020 | Train. Acc.: 92.508% | Loss: 0.259\n",
      "Epoch: 009/020 | Train accuracy: 92.51% | Validation accuracy: 92.78% | Train loss: 0.259| Validation loss: 0.256| Best Validation (Ep. 008): 92.29%\n",
      "Time elapsed: 2.61 min\n",
      "***Epoch: 010/020 | Batch:0000/0469 | Loss: 0.356\n",
      "***Epoch: 010/020 | Batch:0100/0469 | Loss: 0.294\n",
      "***Epoch: 010/020 | Batch:0200/0469 | Loss: 0.266\n",
      "***Epoch: 010/020 | Batch:0300/0469 | Loss: 0.343\n",
      "***Epoch: 010/020 | Batch:0400/0469 | Loss: 0.254\n",
      "***Epoch: 010/020 | Train. Acc.: 92.793% | Loss: 0.250\n",
      "Epoch: 010/020 | Train accuracy: 92.79% | Validation accuracy: 92.87% | Train loss: 0.250| Validation loss: 0.247| Best Validation (Ep. 009): 92.78%\n",
      "Time elapsed: 2.99 min\n",
      "***Epoch: 011/020 | Batch:0000/0469 | Loss: 0.363\n",
      "***Epoch: 011/020 | Batch:0100/0469 | Loss: 0.144\n",
      "***Epoch: 011/020 | Batch:0200/0469 | Loss: 0.284\n",
      "***Epoch: 011/020 | Batch:0300/0469 | Loss: 0.248\n",
      "***Epoch: 011/020 | Batch:0400/0469 | Loss: 0.166\n",
      "***Epoch: 011/020 | Train. Acc.: 93.200% | Loss: 0.237\n",
      "Epoch: 011/020 | Train accuracy: 93.20% | Validation accuracy: 93.26% | Train loss: 0.237| Validation loss: 0.236| Best Validation (Ep. 010): 92.87%\n",
      "Time elapsed: 3.40 min\n",
      "***Epoch: 012/020 | Batch:0000/0469 | Loss: 0.147\n",
      "***Epoch: 012/020 | Batch:0100/0469 | Loss: 0.263\n",
      "***Epoch: 012/020 | Batch:0200/0469 | Loss: 0.328\n",
      "***Epoch: 012/020 | Batch:0300/0469 | Loss: 0.274\n",
      "***Epoch: 012/020 | Batch:0400/0469 | Loss: 0.203\n",
      "***Epoch: 012/020 | Train. Acc.: 93.402% | Loss: 0.228\n",
      "Epoch: 012/020 | Train accuracy: 93.40% | Validation accuracy: 93.43% | Train loss: 0.228| Validation loss: 0.227| Best Validation (Ep. 011): 93.26%\n",
      "Time elapsed: 3.86 min\n",
      "***Epoch: 013/020 | Batch:0000/0469 | Loss: 0.251\n",
      "***Epoch: 013/020 | Batch:0100/0469 | Loss: 0.183\n",
      "***Epoch: 013/020 | Batch:0200/0469 | Loss: 0.149\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from train import training_loop\n",
    "\n",
    "writer = SummaryWriter('runs/mnist/lenet-300-100/%s' % TIMESTAMP)\n",
    "\n",
    "loss, train_acc, val_acc = training_loop(EPOCHS,net,optimizer,device,trainloader,testloader,loss_fn,100,\n",
    "                                         None,'checkpoints/mnist-lenet300-100.pth',writer)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# visualization loss\n",
    "plt.plot(loss)\n",
    "plt.xlabel(\"Number of iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"CNN: Loss vs Number of iteration\")\n",
    "plt.show()\n",
    "\n",
    "# visualization accuracy\n",
    "plt.plot(train_acc,color = \"red\")\n",
    "plt.plot(val_acc,color = \"blue\")\n",
    "plt.xlabel(\"Number of iteration\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"CNN: Accuracy vs Number of iteration\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from prune import threshold_prune\n",
    "\n",
    "s = 2\n",
    "threshold_prune(net,s)\n",
    "\n",
    "writer = SummaryWriter('runs/mnist/lenet-300-100-pruned/%s' % TIMESTAMP)\n",
    "\n",
    "weight_histograms(writer,None,net)\n",
    "\n",
    "torch.save(net.state_dict(), 'checkpoints/mnist-lenet300-100-pruned.pth')\n",
    "plot_sparsity_matrix(net)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from train import evaluate\n",
    "\n",
    "net.load_state_dict(torch.load('checkpoints/mnist-lenet300-100-pruned.pth'))\n",
    "net.to(device)\n",
    "\n",
    "valid_acc, valid_loss = evaluate(net, testloader, device, loss_fn)\n",
    "\n",
    "print('Accuracy after pruning: %.3f%% | Loss: %.3f' % (\n",
    "        valid_acc, valid_loss))\n",
    "\n",
    "writer = SummaryWriter('runs/mnist/lenet-300-100-retrained/%s' % TIMESTAMP)\n",
    "optimizer = optim.SGD(net.parameters(), lr=1e-3,momentum=0.9,weight_decay=1e-5)\n",
    "\n",
    "\n",
    "loss, train_acc, val_acc = training_loop(EPOCHS,net,optimizer,device,trainloader,testloader,loss_fn,100,\n",
    "                                         None,'checkpoints/mnist_lenet300_retrained.pth',writer)\n",
    "\n",
    "plot_sparsity_matrix(net)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# LeNet-5\n",
    "\n",
    "Images need to be rescaled to size 32x32 as described in LeCun et al. 1998"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5),(0.5)),\n",
    "     transforms.Resize(32)])\n",
    "# Load datasets\n",
    "trainloader,testloader = get_mnist_loader(transform,BATCH_SIZE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "print(images.shape, labels.shape)\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images[0:4]))\n",
    "# print labels\n",
    "print(' '.join(f'{labels[j]:1d}' for j in range(4)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from models.lenet import LeNet5\n",
    "\n",
    "net = LeNet5(10)\n",
    "# Try to get GPU device\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "print(device)\n",
    "net.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from train import training_loop\n",
    "\n",
    "loss_fn = F.cross_entropy\n",
    "optimizer = optim.SGD(net.parameters(), lr=1e-3,momentum=0.9,weight_decay=1e-5)\n",
    "\n",
    "lrs = MyMultiStepLR({0:5e-4,2:2e-4,5:1e-4,8:5e-5,12:1e-5})\n",
    "# scheduler = sched.LambdaLR(optimizer,  lrs.get_lr,last_epoch=-1,verbose=True)\n",
    "\n",
    "writer = SummaryWriter('runs/mnist_lenet-5/%s' % TIMESTAMP)\n",
    "\n",
    "loss, train_acc, val_acc = training_loop(EPOCHS,net,optimizer,device,trainloader,testloader,loss_fn,100,None\n",
    "                                         ,'checkpoints/mnist_lenet5.pth',writer)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# visualization loss\n",
    "plt.plot(loss)\n",
    "plt.xlabel(\"Number of iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"CNN: Loss vs Number of iteration\")\n",
    "plt.show()\n",
    "\n",
    "# visualization accuracy\n",
    "plt.plot(train_acc,color = \"red\")\n",
    "plt.plot(val_acc,color = \"blue\")\n",
    "plt.xlabel(\"Number of iteration\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"CNN: Accuracy vs Number of iteration\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "net = LeNet5(10)\n",
    "net.load_state_dict(torch.load('checkpoints/mnist_lenet5.pth'))\n",
    "net.to(device)\n",
    "\n",
    "s = 1\n",
    "threshold_prune(net,s)\n",
    "\n",
    "writer = SummaryWriter('runs/mnist/lenet5-pruned/%s' % TIMESTAMP)\n",
    "\n",
    "weight_histograms(writer,None,net)\n",
    "torch.save(net.state_dict(), 'checkpoints/mnist_lenet5_pruned.pth')\n",
    "\n",
    "valid_acc, valid_loss = evaluate(net, testloader, device, loss_fn)\n",
    "\n",
    "print('Accuracy after pruning: %.3f%% | Loss: %.3f' % (\n",
    "        valid_acc, valid_loss))\n",
    "\n",
    "optimizer = optim.SGD(net.parameters(), lr=1e-3,momentum=0.9,weight_decay=1e-5)\n",
    "writer = SummaryWriter('runs/mnist/lenet5-retrained/%s' % TIMESTAMP)\n",
    "\n",
    "loss, train_acc, val_acc = training_loop(EPOCHS,net,optimizer,device,trainloader,testloader,loss_fn,100,\n",
    "                                         None,'checkpoints/mnist_lenet5_retrained.pth',writer)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
